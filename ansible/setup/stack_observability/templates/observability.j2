job "observability" {
  type = "service"
  datacenters = ["{{data_center}}"]

  group "grafana" {
    volume "stack_observability_grafana_volume" {
      type      = "host"
      source    = "stack_observability_grafana_volume"
      read_only = false
    }

    count = 1
    network {
      mode = "bridge"
      port "ui" {
        to = 3000
      }
    }
    service {
          name = "grafana"
          #      port = "ui"
          port = "3000"
          connect {
            sidecar_service {
#              proxy {
#                config {
#                   protocol = "http"
#                }
#            }
          }
        }
        tags = [
          "traefik.enable=true",
          "traefik.consulcatalog.connect=true",
          "traefik.http.routers.grafana.tls=true",
          "traefik.http.routers.grafana.rule=Host(`grafana.{{tls_san}}`)",
        ]

        check {
          name     = "health"
          type     = "http"
          port     = "ui"
          path     = "/health"
          interval = "10s"
          timeout  = "2s"
        }
    }
    task "grafana" {
     volume_mount {
        volume      = "stack_observability_grafana_volume"
        destination = "/var/lib/grafana"
      }

      driver = "docker"
      env {
        GF_AUTH_OAUTH_AUTO_LOGIN= "true"
        GF_PATHS_CONFIG  = "/etc/grafana/grafana2.ini"
        GF_PATHS_PLUGINS = "/data/grafana/plugins"
        GF_SERVER_DOMAIN = "grafana.{{tls_san}}"
        GF_SERVER_ROOT_URL = "https://grafana.{{tls_san}}"
        GF_AUTH_GENERIC_OAUTH_ROLE_ATTRIBUTE_PATH = "contains(realm_access.roles[*], 'admin') && 'GrafanaAdmin' || contains(realm_access.roles[*], 'editor') && 'Editor' || 'Viewer'"
      }
      config {
        image = "{{registry_dns}}/{{stack_name}}/grafana:{{version_grafana_nomadder}}"
        ports = ["ui"]
      }
      resources {
        cpu    = 1000
        memory = 2048
      }
      template {
         destination = "${NOMAD_SECRETS_DIR}/env.vars"
         env         = true
         change_mode = "restart"
         data        = <<EOF
          {{ '{{' }} with nomadVar "{{nomad_observability_job_path}}" {{ '}}' }}
            GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET    = {{ '{{' }}.keycloak_secret_observability_grafana{{ '}}' }}
          {{ '{{' }} end {{ '}}' }}
          EOF
      }
    }
  }

  group "mimir"{
    volume "stack_observability_mimir_volume" {
      type      = "host"
      source    = "stack_observability_mimir_volume"
      read_only = false
    }
      count = 1
      network {
        mode = "bridge"
        port "api" {
          static= 9009
          to = 9009
        }
      }


    service{
      name ="mimir"
      port= "api"
      check {
        name  = "health"
        type  = "http"
        port ="api"
        path="/ready"
        interval = "10s"
        timeout  = "2s"
       }
    }
      task "mimir"{
        volume_mount {
          volume      = "stack_observability_mimir_volume"
          destination = "/data"
        }

         driver = "docker"
         config {
         image = "{{registry_dns}}/grafana/mimir:{{version_grafana_mimir}}"
         ports = ["api"]
         args = [
           "-config.file","/config/mimir.yaml"
         ]
        volumes = [
          "local/mimir.tpl:/config/mimir.yaml"
        ]
         }
      resources {
        cpu    = 1000
        memory = 2048
      }

   artifact {
     source      = "https://nexus.{{tls_san}}/repository/raw/config/stack/observability/mimir.yaml"
     mode= "file"
     destination = "local/mimir.tpl"
   }


    template {
      change_mode   = "restart"
      right_delimiter = "++"
      left_delimiter = "++"
      source        = "local/mimir.tpl"
      destination = "local/mimir.yaml"
    }


 #     template {
 #       change_mode   = "restart"
 #       destination = "local/mimir.tpl"
 #       right_delimiter = "++"
 #       left_delimiter = "++"
 #       data        = <<EOH
 #       ++ with nomadVar "{{nomad_observability_job_path}}"  ++
 #         ++ .mimir_config ++
 #        ++ end  ++
 #       EOH
 #       }

    }
  }
 group "loki"{
    volume "stack_observability_loki_volume" {
      type      = "host"
      source    = "stack_observability_loki_volume"
      read_only = false
    }
    count = 1
    network {
      mode = "bridge"
      port "http" {
        static = 3100
        to = 3100
      }
      port "cli" {
        static = 7946
        to = 7946
      }
      port "grpc" {
        static = 9005
        to = 9095
      }
    }

 service {
   name ="loki"
   port= "http"
   check {
     name  = "health"
     type  = "http"
     port ="http"
     path="/ready"
     interval = "10s"
     timeout  = "2s"
    }
 }

     task "loki"{
       volume_mount {
         volume      = "stack_observability_loki_volume"
         destination = "/data"
       }

     driver = "docker"
     env {
       JAEGER_AGENT_HOST= "${NOMAD_UPSTREAM_IP_tempo_jaeger}"
       JAEGER_ENDPOINT = "http://${NOMAD_UPSTREAM_ADDR_tempo_jaeger}/api/traces" # send traces to Tempo
       JAEGER_SAMPLER_TYPE = const
       JAEGER_SAMPLER_PARAM = 1
       }
    config {
       image = "{{registry_dns}}/grafana/loki:{{version_grafana_loki}}"
       ports = ["http","cli","grpc"]
       args = [
        "-config.file","/config/loki.yaml"
       ]
    volumes = [
      "local/loki.tpl:/config/loki.yaml"
      ]
    }
    resources {
       cpu    = 1000
       memory = 2048
    }

     artifact {
       source      = "https://nexus.{{tls_san}}/repository/raw/config/stack/observability/loki.yaml"
       mode= "file"
       destination = "local/loki.tpl"
     }

      template {
        change_mode   = "restart"
        right_delimiter = "++"
        left_delimiter = "++"
        source        = "local/loki.tpl"
        destination = "local/loki.yaml"
      }
      }
    }
  group "tempo"{


    volume "stack_observability_tempo_volume" {
      type      = "host"
      source    = "stack_observability_tempo_volume"
      read_only = false
    }
      count = 1
      network {
        mode = "bridge"
        port "jaeger" {
          static =  14268
          to = 14268
        }
        port "tempo" {
          static =  3200
          to = 3200
        }
        port "otlp_grpc" {
          static =  4317
          to = 4317
        }
        port "otlp_http" {
          static =  4318
          to = 4318
        }
        port "zipkin" {
          static =  9411
          to = 9411
        }
      }
    service{
      name ="tempo"
      port= "tempo"
      check {
        name  = "health"
        type  = "http"
        port ="tempo"
        path="/ready"
        interval = "10s"
        timeout  = "2s"
       }
    }
    service{
       name ="tempo-zipkin"
       port= "zipkin"
       check {
         name     = "tempo_zipkin_check"
         type     = "tcp"
         interval = "10s"
         timeout  = "1s"
        }
       }
     service{
        name ="tempo-jaeger"
        port= "jaeger"
        check {
          name     = "tempo_jagger_check"
          type     = "tcp"
          interval = "10s"
          timeout  = "1s"
         }
      }
     service{
        name ="tempo-otlp-grpc"
        port= "otlp_grpc"
        check {
          name     = "tempo_otlp_grpc_check"
          type     = "tcp"
          interval = "10s"
          timeout  = "1s"
         }
      }
     service{
        name ="tempo-otlp-http"
        port= "otlp_http"
        check {
          name     = "tempo_otlp_http_check"
          type     = "tcp"
          interval = "10s"
          timeout  = "1s"
         }
      }
      task "tempo"{
        volume_mount {
          volume      = "stack_observability_tempo_volume"
          destination = "/data"
        }

         driver = "docker"
         config {
         image = "{{registry_dns}}/grafana/tempo:{{version_grafana_tempo}}"
         ports = ["jaeger","tempo","otlp_grpc","otlp_http","zipkin"]
         args = [
           "-config.file","/config/tempo.yaml"
         ]
        volumes = [
          "local/tempo.yaml:/config/tempo.yaml"
        ]
         }
      resources {
        cpu    = 1000
        memory = 2048
      }


   artifact {
     source      = "https://nexus.{{tls_san}}/repository/raw/config/stack/observability/tempo.yaml"
     mode= "file"
     destination = "local/tempo.tpl"
   }

    template {
      change_mode   = "restart"
      right_delimiter = "++"
      left_delimiter = "++"
      source        = "local/tempo.tpl"
      destination = "local/tempo.yaml"
    }
    }
  }

    group "nats"{
       volume "stack_observability_nats_volume" {
          type      = "host"
          source    = "stack_observability_nats_volume"
          read_only = false
        }
     count = 1
      restart {
           attempts = 10
           interval = "5m"
           delay    = "25s"
           mode     = "delay"
         }
      network {
        mode = "bridge"
        port "client" {
          static =  4222
          to = 4222
        }
        port "http" {
          static =  8222
          to = 8222
        }
        port "cluster" {
          static =  6222
          to = 6222
        }
        port "prometheus-exporter" {
            to = 7222
        }

      }
        service {
              port = "client"
              name = "nats"

              check {
                 type     = "http"
                 port     = "http"
                 path     = "/connz"
                 interval = "5s"
                 timeout  = "2s"
              }
      }

        service {
           port = "prometheus-exporter"
           name = "prometheus-exporter"
           check {
              type     = "http"
              port     = "http"
              path     = "/v1/metrics"
              interval = "5s"
              timeout  = "2s"
           }
      }

      task "nats-prometheus-exporter" {
        lifecycle {
          hook = "poststart"
          sidecar = true
        }

        driver = "docker"
        config {
            image = "{{registry_dns}}/natsio/prometheus-nats-exporter:{{version_nats_prometheus_exporter}}"
            ports = ["prometheus_exporter"]
            args = [
              "-varz",
              "-channelz",
              "-connz",
              "-gatewayz",
              "-leafz",
              "-serverz",
              "-subz",
              "-jsz=all",
              "http://localhost:8222"
            ]
        }
      }

    task "nats" {
         volume_mount {
            volume      = "stack_observability_nats_volume"
            destination = "/data/jetstream"
          }
             driver = "docker"
             config {
             image = "{{registry_dns}}/nats:{{version_nats_server}}-alpine"
             ports = ["client","http","cluster"]
             args = [
               "-c","/config/nats.conf"
             ]
            volumes = [
              "local/nats.conf:/config/nats.conf"
            ]
             }
          resources {
            cpu    = 2000
            memory = 2048
          }
          template {
             destination = "local/nats.conf"
             change_mode = "restart"
             right_delimiter = "++"
             left_delimiter = "++"
             data        = <<EOF
# Client port of 4222 on all interfaces
port: 4222

# HTTP monitoring port
monitor_port: 8222
server_name: $NOMAD_TASK_NAME
trace: true
http_port: 8222


jetstream {
  store_dir: /data/jetstream

  # 1GB
  max_memory_store: 2G

  # 10GB
  max_file_store: 10G
}
              EOF
          }
       }

    }
  group "grafana-agent"{
       # Grafana agent is deployed on every node and scrapes the general nomad job metrics
       # This agent deployed is for scraping special service metrics like databases brokers etc
       volume "stack_observability_grafana_agent_volume" {
          type      = "host"
          source    = "stack_observability_grafana_agent_volume"
          read_only = false
        }
          count = 1
           restart {
                attempts = 10
                interval = "5m"
                delay    = "25s"
                mode     = "delay"
              }
    task "grafana-agent" {
         volume_mount {
            volume      = "stack_observability_grafana_agent_volume"
            destination = "/data/wal"
          }
       driver = "docker"
       config {

         image = "{{registry_dns}}/grafana/agent:v{{version_grafana_agent}}"
         args = [
             "-config.file","/config/agent.yaml"
          ]
          volumes = [
            "local/agent.yaml:/config/agent.yaml"
        ]
        }
        resources {
          cpu    = 500
          memory = 256
        }
template {
 destination = "local/agent.yaml"
 change_mode = "restart"
 right_delimiter = "++"
 left_delimiter = "++"
 data        = <<EOF
server:
  log_level: debug

metrics:
  wal_directory: "/data/wal"
  global:
    scrape_interval: 5s
    remote_write:
      - url: http://mimir.service.consul:9009/api/v1/push

              EOF
  }
  }
  }
}