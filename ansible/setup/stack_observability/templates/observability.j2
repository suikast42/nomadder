variable "org" {
  type = string
  description = "Default organisation"
  default = "{{tls_san}}"
}

variable "env" {
  type = string
  description = "environment like prod dev testing"
  default = "{{env}}"
}

job "observability" {
 {% if is_env_development %}
# Enable this for redeploy all the job file even if nothing changed
#  meta {
#    run_uuid = "${uuidv4()}"
#  }
#
  {% endif %}

  type = "service"
  datacenters = ["{{data_center}}"]
  reschedule {
    delay          = "10s"
    delay_function = "constant"
    unlimited      = true
  }
  update {
      health_check      = "checks"
      max_parallel      = 1
      # Alloc is marked as unhealthy after this time
      healthy_deadline  = "5m"
      auto_revert  = true
      # Mark the task as healthy after 10s positive check
      min_healthy_time  = "10s"
      # Task is dead after failed checks in 1h
      progress_deadline = "1h"
  }
  group "grafana" {
    restart {
      attempts = 1
      interval = "1h"
      delay = "5s"
      mode = "fail"
    }

    volume "stack_observability_grafana_volume" {
      type      = "host"
      source    = "stack_observability_grafana_volume"
      read_only = false
    }

    count = 1
    network {
      mode = "bridge"
      port "ui" {
        to = 3000
      }
    }
    service {
          name = "grafana"
          #      port = "ui"
          port = "3000"
          connect {
            sidecar_service {
#              proxy {
#                config {
#                   protocol = "http"
#                }
#            }
          }
            sidecar_task{
              config{
               {% if set_cpu_hard_limit %}
                cpu_hard_limit = "true"
               {% endif %}
                labels = {
                  "com.github.logunifier.application.pattern.key" = "envoy"
                  "com.github.logunifier.application.name" = "grafana_agent"
                  "com.github.logunifier.application.version" = "{{version_grafana_agent_container}}"
                  "com.github.logunifier.application.org" = "${var.org}"
                  "com.github.logunifier.application.env" = "${var.env}"
                }
              }
            }
        }
        tags = [
          "traefik.enable=true",
          "traefik.consulcatalog.connect=true",
          "traefik.http.routers.grafana.tls=true",
          "traefik.http.routers.grafana.rule=Host(`grafana.{{tls_san}}`)",
        ]

        check {
          name     = "health"
          type     = "http"
          port     = "ui"
          path     = "/healthz"
          interval = "10s"
          timeout  = "2s"
          check_restart {
            limit = 3
            grace = "60s"
            ignore_warnings = false
          }
        }
    }
    task "grafana" {
     volume_mount {
        volume      = "stack_observability_grafana_volume"
        destination = "/var/lib/grafana"
      }

      driver = "docker"
      env {
        GF_AUTH_OAUTH_AUTO_LOGIN= "true"
        GF_AUTH_OAUTH_ALLOW_INSECURE_EMAIL_LOOKUP= "true"
        GF_PATHS_CONFIG  = "/etc/grafana/grafana2.ini"
        GF_PATHS_PLUGINS = "/data/grafana/plugins"
        GF_SERVER_DOMAIN = "grafana.{{tls_san}}"
        GF_SERVER_ROOT_URL = "https://grafana.{{tls_san}}"
        GF_AUTH_GENERIC_OAUTH_ROLE_ATTRIBUTE_PATH = "contains(realm_access.roles[*], 'admin') && 'GrafanaAdmin' || contains(realm_access.roles[*], 'editor') && 'Editor' || 'Viewer'"
      }
      config {
        image = "{{registry_dns}}/{{stack_name}}/grafana:{{version_grafana_nomadder}}"
 {% if set_cpu_hard_limit %}
        cpu_hard_limit = "true"
 {% endif %}
        labels = {
          "com.github.logunifier.application.name" = "grafana"
          "com.github.logunifier.application.version" = "{{version_grafana_nomadder}}"
          "com.github.logunifier.application.org" = "${var.org}"
          "com.github.logunifier.application.env" = "${var.env}"
          "com.github.logunifier.application.pattern.key" = "logfmt"
        }
        ports = ["ui"]
      }
      resources {
        cpu    = 500
        memory = 1024
        memory_max = 4096
      }
      template {
         destination = "${NOMAD_SECRETS_DIR}/env.vars"
         env         = true
         change_mode = "restart"
         data        = <<EOF
          {{ '{{' }} with nomadVar "{{nomad_observability_job_path}}" {{ '}}' }}
            GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET    = {{ '{{' }}.keycloak_secret_observability_grafana{{ '}}' }}
          {{ '{{' }} end {{ '}}' }}
          EOF
      }
    }
  }

  group "mimir"{
    restart {
      attempts = 1
      interval = "1h"
      delay = "5s"
      mode = "fail"
    }
    volume "stack_observability_mimir_volume" {
      type      = "host"
      source    = "stack_observability_mimir_volume"
      read_only = false
    }
      count = 1
      network {
        mode = "bridge"
        port "api" {
          static= 9009
          to = 9009
        }
      }


    service{
      name ="mimir"
      port= "api"
      check {
        name  = "health"
        type  = "http"
        port ="api"
        path="/ready"
        interval = "10s"
        timeout  = "2s"
        check_restart {
          limit = 3
          grace = "60s"
          ignore_warnings = false
        }
       }
    }
      task "mimir"{
        volume_mount {
          volume      = "stack_observability_mimir_volume"
          destination = "/data"
        }

         driver = "docker"
   #      env {
   #        JAEGER_ENDPOINT = "http://tempo-jaeger.service.consul:14268/api/traces?format=jaeger.thrift" # send traces to Tempo
   #        JAEGER_REPORTER_LOG_SPANS=true
   #        JAEGER_TRACEID_128BIT=true
   #        JAEGER_SAMPLER_TYPE="const"
   #        JAEGER_SAMPLER_PARAM="1"
   #      }
         config {
         image = "{{registry_dns}}/grafana/mimir:{{version_grafana_mimir}}"
 {% if set_cpu_hard_limit %}
         cpu_hard_limit = "true"
 {% endif %}
         labels = {
           "com.github.logunifier.application.name" = "mimir"
           "com.github.logunifier.application.version" = "{{version_grafana_mimir}}"
           "com.github.logunifier.application.org" = "${var.org}"
           "com.github.logunifier.application.env" = "${var.env}"
           "com.github.logunifier.application.pattern.key" = "logfmt"
         }
         ports = ["api"]
         args = [
           "-config.file","/config/mimir.yaml","-config.expand-env","true",
         ]
        volumes = [
          "local/mimir.yml:/config/mimir.yaml"
        ]
         }
      resources {
        cpu    = 2100
        memory = 2048
        memory_max = 32768
      }
    template {
      change_mode   = "restart"
      right_delimiter = "++"
      left_delimiter = "++"
      data = <<EOF

# Test ++ env "NOMAD_ALLOC_NAME"  ++
# Do not use this configuration in production.
# It is for demonstration purposes only.

# Run Mimir in single process mode, with all components running in 1 process.
target: all,alertmanager,overrides-exporter
# Disable tendency support.
multitenancy_enabled: false

server:
  http_listen_port: 9009
  log_level: info
  # Configure the server to allow messages up to 100MB.
  grpc_server_max_recv_msg_size: 104857600
  grpc_server_max_send_msg_size: 104857600
  grpc_server_max_concurrent_streams: 1000

blocks_storage:
  backend: filesystem
  bucket_store:
    sync_dir: /data/tsdb-sync
   #ignore_blocks_within: 10h # default 10h
  filesystem:
    dir: /data/blocks
  tsdb:
    dir: /data/tsdb
    # Note that changing this requires changes to some other parameters like
    # -querier.query-store-after,
    # -querier.query-ingesters-within and
    # -blocks-storage.bucket-store.ignore-blocks-within.
{% if is_env_development  %}
    retention_period: 24h # default 24h
{% else %}
    retention_period: 720h
{% endif %}


querier:
  # query_ingesters_within: 13h # default 13h
  #query_store_after: 12h #default 12h

ruler_storage:
  backend: filesystem
  filesystem:
    dir: /data/rules

alertmanager_storage:
  backend: filesystem
  filesystem:
    dir: /data/alarms

frontend:
  grpc_client_config:
    grpc_compression: snappy

frontend_worker:
  grpc_client_config:
    grpc_compression: snappy

ingester_client:
  grpc_client_config:
    grpc_compression: snappy

query_scheduler:
  grpc_client_config:
    grpc_compression: snappy

alertmanager:
  data_dir: /data/alertmanager
{% if is_env_development  %}
  retention: 24h
{% else %}
  retention: 720h
{% endif %}

  sharding_ring:
    replication_factor: 1
  alertmanager_client:
    grpc_compression: snappy

ruler:
  # Somehow the consul address does not works here
  alertmanager_url: http://localhost:9009/alertmanager
  query_frontend:
    grpc_client_config:
      grpc_compression: snappy

compactor:
#  compaction_interval: 1h # default 1h
#  deletion_delay: 12h # default 12h
  max_closing_blocks_concurrency: 2
  max_opening_blocks_concurrency: 4
  symbols_flushers_concurrency: 4
  data_dir: /data/compactor
  sharding_ring:
    kvstore:
      store: memberlist


ingester:
  ring:
    replication_factor: 1

store_gateway:
  sharding_ring:
    replication_factor: 1

limits:
  # Limit queries to 5 years. You can override this on a per-tenant basis.
  max_total_query_length: 43680h
  max_label_names_per_series: 42
  # Allow ingestion of out-of-order samples up to 2 hours since the latest received sample for the series.
  out_of_order_time_window: 1d
  # delete old blocks from long-term storage.
{% if is_env_development  %}
  # Delete from storage metrics data older than 1d.
  compactor_blocks_retention_period: 1d
{% else %}
  # Delete from storage metrics data older than 720h.
  compactor_blocks_retention_period: 720h
{% endif %}

  ingestion_rate: 100000
      EOF
      destination = "local/mimir.yml"
    }

#    template {
#      change_mode   = "restart"
#      right_delimiter = "++"
#      left_delimiter = "++"
#      data = file(abspath("./configs/mimir/mimir.tpl"))
#      destination = "local/mimir.yml"
#    }


 #     template {
 #       change_mode   = "restart"
 #       destination = "local/mimir.tpl"
 #       right_delimiter = "++"
 #       left_delimiter = "++"
 #       data        = <<EOH
 #       ++ with nomadVar "{{nomad_observability_job_path}}"  ++
 #         ++ .mimir_config ++
 #        ++ end  ++
 #       EOH
 #       }

    }
  }
 group "loki"{
    restart {
      attempts = 1
      interval = "1h"
      delay = "5s"
      mode = "fail"
    }
    update {
       max_parallel      = 1
    }
    volume "stack_observability_loki_volume" {
      type      = "host"
      source    = "stack_observability_loki_volume"
      read_only = false
    }
    count = 1
    network {
      mode = "bridge"
      port "http" {
        static = 3100
        to = 3100
      }
      port "cli" {
        static = 7946
        to = 7946
      }
      port "grpc" {
        static = 9005
        to = 9095
      }
    }

     service {
       name ="loki"
       port= "http"
       tags = [
             "prometheus",
             "prometheus:server_id=${NOMAD_ALLOC_NAME}",
             "prometheus:version={{version_grafana_loki}}",
          ]
       check {
         name  = "health"
         type  = "http"
         port ="http"
         path="/ready"
         interval = "10s"
         timeout  = "2s"
         check_restart {
           limit = 3
           grace = "60s"
           ignore_warnings = false
         }
        }
     }

     task "loki"{
       volume_mount {
         volume      = "stack_observability_loki_volume"
         destination = "/data"
       }

     driver = "docker"
   #  env {
   #    JAEGER_ENDPOINT = "http://tempo-jaeger.service.consul:14268/api/traces?format=jaeger.thrift" # send traces to Tempo
   #    JAEGER_REPORTER_LOG_SPANS=true
   #    JAEGER_TRACEID_128BIT=true
   #    JAEGER_SAMPLER_TYPE="const"
   #    JAEGER_SAMPLER_PARAM="1"
   #  }
    config {
       image = "{{registry_dns}}/grafana/loki:{{version_grafana_loki}}"
  {% if set_cpu_hard_limit %}
       cpu_hard_limit = "true"
  {% endif %}
       labels = {
         "com.github.logunifier.application.name" = "loki"
         "com.github.logunifier.application.version" = "{{version_grafana_loki}}"
         "com.github.logunifier.application.org" = "${var.org}"
         "com.github.logunifier.application.env" = "${var.env}"
         "com.github.logunifier.application.pattern.key" = "logfmt"
       }
       ports = ["http","cli","grpc"]
       args = [
        "-config.file","/config/loki.yaml","-config.expand-env","true","-print-config-stderr","true",
       ]
    volumes = [
      "local/loki.yaml:/config/loki.yaml"
      ]
    }
    resources {
       cpu    = 1000
       memory = 1024
       memory_max = 32768
    }
      template {
        change_mode   = "restart"
        right_delimiter = "++"
        left_delimiter = "++"
        data = <<EOF
auth_enabled: false

server:
  #default 3100
  http_listen_port: 3100
  #default 9005
  #grpc_listen_port: 9005
  # Max gRPC message size that can be received
  # CLI flag: -server.grpc-max-recv-msg-size-bytes
  #default 4194304 -> 4MB
  grpc_server_max_recv_msg_size: 419430400

  # Max gRPC message size that can be sent
  # CLI flag: -server.grpc-max-send-msg-size-bytes
  #default 4194304 -> 4MB
  grpc_server_max_send_msg_size:  419430400

  # Limit on the number of concurrent streams for gRPC calls (0 = unlimited)
  # CLI flag: -server.grpc-max-concurrent-streams
  grpc_server_max_concurrent_streams:  100

  # Log only messages with the given severity or above. Supported values [debug,
  # info, warn, error]
  # CLI flag: -log.level
  log_level: "warn"
ingester:
  wal:
    enabled: true
    dir: /data/wal
  lifecycler:
    address: 127.0.0.1
    ring:
      kvstore:
        store: memberlist
      replication_factor: 1
    final_sleep: 0s
  chunk_idle_period: 5m
  chunk_retain_period: 30s
  chunk_encoding: snappy

ruler:
  evaluation_interval : 1m
  poll_interval: 1m
  storage:
    type: local
    local:
      directory: /data/rules
  rule_path: /data/scratch
++- range  $index, $service := service "mimir" -++
++- if eq $index 0 ++
  alertmanager_url: http://++$service.Name++.service.consul:++ $service.Port ++/alertmanager
++- end ++
++- end ++

  ring:
    kvstore:
      store: memberlist
  enable_api: true
  enable_alertmanager_v2: true

compactor:
  working_directory: /data/retention
  delete_request_store: filesystem
  compaction_interval: 10m
  retention_enabled: true
  retention_delete_delay: 2h
  retention_delete_worker_count: 150

schema_config:

  configs:
    - from: 2024-04-01
      object_store: filesystem
      store: tsdb
      schema: v13
      index:
        prefix: index_
        period: 24h

storage_config:
  tsdb_shipper:
    active_index_directory: /data/index-tsdb
    cache_location: /data/index-cache-tsdb
  boltdb_shipper:
    active_index_directory: /data/index
    cache_location: /data/index-cache
  filesystem:
    directory: /data/chunks
  index_queries_cache_config:
    embedded_cache:
      max_size_mb: 4096
      enabled: true
querier:
  multi_tenant_queries_enabled: false
  max_concurrent: 4096
  query_store_only: false

query_scheduler:
  max_outstanding_requests_per_tenant: 10000

query_range:
  cache_results: true
  results_cache:
    cache:
      embedded_cache:
        enabled: true

chunk_store_config:
  chunk_cache_config:
    embedded_cache:
      max_size_mb: 4096
      enabled: true
  write_dedupe_cache_config:
    embedded_cache:
      max_size_mb: 4096
      enabled: true

distributor:
  ring:
    kvstore:
      store: memberlist

table_manager:
  retention_deletes_enabled: true
  retention_period: 24h

limits_config:
  ingestion_rate_mb: 64
  ingestion_burst_size_mb: 8
  max_label_name_length: 4096
  max_label_value_length: 8092
  # Loki will reject any log lines that have already been processed and will not index them again
  reject_old_samples: false
  # 5y
  reject_old_samples_max_age: 43800h
  # The limit to length of chunk store queries. 0 to disable.
  # 5y
  max_query_length: 43800h
  # Maximum number of log entries that will be returned for a query.
  max_entries_limit_per_query: 20000
  # Limit the maximum of unique series that is returned by a metric query.
  max_query_series: 100000
  # Maximum number of queries that will be scheduled in parallel by the frontend.
  max_query_parallelism: 64
  split_queries_by_interval: 24h
  # Alter the log line timestamp during ingestion when the timestamp is the same as the
  # previous entry for the same stream. When enabled, if a log line in a push request has
  # the same timestamp as the previous line for the same stream, one nanosecond is added
  # to the log line. This will preserve the received order of log lines with the exact
  # same timestamp when they are queried, by slightly altering their stored timestamp.
  # NOTE: This is imperfect, because Loki accepts out of order writes, and another push
  # request for the same stream could contain duplicate timestamps to existing
  # entries and they will not be incremented.
  # CLI flag: -validation.increment-duplicate-timestamps
  increment_duplicate_timestamp: true
  #Log data retention for all
{% if is_env_development  %}
  retention_period: 24h
  max_query_lookback: 24h
{% else %}
  retention_period: 720h
  max_query_lookback: 720h
{% endif %}

  # Comment this out for fine grained retention
#  retention_stream:
#  - selector: '{namespace="dev"}'
#    priority: 1
#    period: 24h
  # Comment this out for having overrides
#  per_tenant_override_config: /etc/overrides.yaml
         EOF
        destination = "local/loki.yaml"
      }

#      template {
#        change_mode   = "restart"
#        right_delimiter = "++"
#        left_delimiter = "++"
#        data = file(abspath("./configs/loki/loki.tpl"))
#        destination = "local/loki.yaml"
#      }
      }
    }
  group "tempo"{
    restart {
      attempts = 1
      interval = "1h"
      delay = "5s"
      mode = "fail"
    }
    volume "stack_observability_tempo_volume" {
      type      = "host"
      source    = "stack_observability_tempo_volume"
      read_only = false
    }
      count = 1
      network {
        mode = "bridge"
        # Query api for tempo itself
        port "tempo" {
          static =  3200
          to = 3200
        }
        # server grpc port
        # 9095
#        port "zipkin" {
#          static =  9411
#          to = 9411
#        }
#        port "jaeger_http" {
#          static =  14268
#          to = 14268
#        }
#        port "jaeger_grpc" {
#          static =  14250
#          to = 14250
#        }
        port "otlp_grpc" {
          static =  4317
          to = 4317
        }
        port "otlp_http" {
          static =  4318
          to = 4318
        }
#        port "opensus" {
#          static =  55678
#          to = 55678
#        }

      }
    service{
      name ="tempo"
      port= "tempo"
      check {
        name  = "health"
        type  = "http"
        port ="tempo"
        path="/ready"
        interval = "10s"
        timeout  = "2s"
        check_restart {
          limit = 3
          grace = "60s"
          ignore_warnings = false
        }
       }
    }
#    service{
#       name ="tempo-zipkin"
#       port= "zipkin"
#       check {
#         name     = "tempo_zipkin_check"
#         type     = "tcp"
#         interval = "10s"
#         timeout  = "1s"
#        }
#    }
#    service{
#       name ="jaeger-http"
#       port= "jaeger_http"
#       check {
#         name     = "jaeger_http_check"
#         type     = "tcp"
#         interval = "10s"
#         timeout  = "1s"
#        }
#    }
#    service{
#       name ="jaeger-grpc"
#       port= "jaeger_grpc"
#       check {
#         name     = "jaeger_grpc_check"
#         type     = "tcp"
#         interval = "10s"
#         timeout  = "1s"
#        }
#    }
    service{
       name ="otlp-http"
       port= "otlp_http"
       check {
         name     = "otlp_http_check"
         type     = "tcp"
         interval = "10s"
         timeout  = "1s"
        }
    }
    service{
       name ="otlp-grpc"
       port= "otlp_grpc"
       check {
         name     = "otlp_grpc_check"
         type     = "tcp"
         interval = "10s"
         timeout  = "1s"
        }
    }
      task "tempo"{
        volume_mount {
          volume      = "stack_observability_tempo_volume"
          destination = "/data"
        }

         driver = "docker"
       #   env {
       #   # Not needed for tempo itself
       #  #   JAEGER_ENDPOINT = "http://tempo-jaeger.service.consul:14268/api/traces?format=jaeger.thrift" # send traces to Tempo
       #     JAEGER_REPORTER_LOG_SPANS=true
       #     JAEGER_TRACEID_128BIT=true
       #     JAEGER_SAMPLER_TYPE="const"
       #     JAEGER_SAMPLER_PARAM="1"
       #   }
         config {
         image = "{{registry_dns}}/grafana/tempo:{{version_grafana_tempo}}"
 {% if set_cpu_hard_limit %}
         cpu_hard_limit = "true"
 {% endif %}
         labels = {
           "com.github.logunifier.application.name" = "tempo"
           "com.github.logunifier.application.version" = "{{version_grafana_tempo}}"
           "com.github.logunifier.application.org" = "${var.org}"
           "com.github.logunifier.application.env" = "${var.env}"
           "com.github.logunifier.application.pattern.key" = "logfmt"
         }
     #    ports = ["zipkin","jaeger_http","jaeger_grpc","otlp_http","otlp_grpc"]
         ports = ["otlp_http","otlp_grpc"]
         args = [
           "-config.file","/config/tempo.yaml","-config.expand-env","true"
         ]
        volumes = [
          "local/tempo.yaml:/config/tempo.yaml"
        ]
         }
      resources {
        cpu    = 1024
        memory = 1024
        memory_max = 32768
      }

     template {
       change_mode   = "restart"
       right_delimiter = "++"
       left_delimiter = "++"
       data = <<EOF
multitenancy_enabled: false

server:
  http_listen_port: 3200
  #default
  #grpc_listen_port: 9095

distributor:
  receivers:                           # this configuration will listen on all ports and protocols that tempo is capable of.
#    jaeger:                            # the receives all come from the OpenTelemetry collector.  more configuration information can
#      protocols:                       # be found there: https://github.com/open-telemetry/opentelemetry-collector/tree/main/receiver
#        thrift_http:                   #
#        grpc:                          # for a production deployment you should only enable the receivers you need!
#        thrift_binary:
#        thrift_compact:
#    zipkin:
    otlp:
      protocols:
        http:
        grpc:
#    opencensus:

ingester:
  trace_idle_period: 10s              # amount of time a trace must be idle before flushing it to the wal.
  max_block_bytes: 524288000          # maximum size of a block before cutting it 500MB
  max_block_duration: 30m             # maximum length of time before cutting a block
  complete_block_timeout: 15m         # duration to keep blocks in the ingester after they have been flushed

query_frontend:
  search:
    max_duration: 43800h # 5y
    query_backend_after: 15m  # (default: 15m)  query_backend_after must be less than or equal to query_ingesters_until.
    query_ingesters_until: 15m    # (default: 30m)
#    max_duration: 336h    # The maximum allowed time range for a search.  (default: 168h) 0 disables this limit.
#    max_result_limit: 400   # The default value of 0 disables this limit.
#    default_result_limit: 20 #  (default: 20)


compactor:
  compaction:
    compaction_window: 1h              # blocks in this time window will be compacted together
    max_block_bytes: 100_000_000       # maximum size of compacted blocks
{% if is_env_development  %}
    block_retention: 24h               # Duration to keep blocks 14d
{% else %}
    block_retention: 720h
{% endif %}

metrics_generator:
  processor:
    span_metrics:
      dimensions: [org.name, deployment.environment, db.name,db.operation, messaging.operation, messaging.destination.name, messaging.sender]
  registry:
    external_labels:
      source: tempo
      cluster: {{data_center}}
  traces_storage:
    path: /data/generator/traces
  storage:
    path: /data/generator/wal
    remote_write:
++- range service "mimir" ++
      - url: http://++.Name++.service.consul:++.Port++/api/v1/push
        send_exemplars: true
        headers:
          x-scope-orgid: 1
++- end ++


storage:
  trace:
    backend: local                     # backend configuration to use
    block:
      bloom_filter_false_positive: .05 # bloom filter false positive rate.  lower values create larger filters but fewer false positives
    wal:
      path: /data/wal             # where to store the the wal locally
    local:
      path: /data/blocks
    pool:
      max_workers: 100                 # worker pool determines the number of parallel requests to the object store backend
      queue_depth: 10000

overrides:
  defaults:
    metrics_generator:
      processors:
        - service-graphs
        - span-metrics
        - local-blocks
       EOF
       destination = "local/tempo.yaml"
     }
    }
  }

    group "nats"{
        restart {
          attempts = 1
          interval = "1h"
          delay = "5s"
          mode = "fail"
        }
     update {
        max_parallel      = 1
     }
       volume "stack_observability_nats_volume" {
          type      = "host"
          source    = "stack_observability_nats_volume"
          read_only = false
        }
     count = 1
      network {
        mode = "bridge"
        port "client" {
          static =  4222
          to = 4222
        }
        port "http" {
          to = 8222
        }
        port "cluster" {
          to = 6222
        }
        port "prometheus-exporter" {
              to = 7777
        }

      }
      service {
        port = "client"
        name = "nats-observability"
        tags = [
            "prometheus",
            "prometheus:server_id=nats-observability",
            "prometheus:version={{version_nats_server}}",
        ]
        check {
          type     = "http"
          port     = "http"
          path     = "/healthz"
          interval = "10s"
          timeout  = "2s"
          check_restart {
            limit = 3
            grace = "60s"
            ignore_warnings = false
            }
          }
      }

        service {
           port = "prometheus-exporter"
           # Change the service selector in grafana agent config as well if you cange this name
           name = "${NOMAD_ALLOC_NAME}"
           tags = [
                "prometheus",
                "prometheus:server_id=${NOMAD_ALLOC_NAME}",
                "prometheus:version={{version_nats_prometheus_exporter}}",
           ]
           check {
              type     = "http"
              port     = "prometheus-exporter"
              path     = "/metrics"
              interval = "5s"
              timeout  = "2s"
              check_restart {
                limit = 3
                grace = "60s"
                ignore_warnings = false
               }
           }
      }
      task "nats-prometheus-exporter" {
        lifecycle {
          hook = "poststart"
          sidecar = true
        }

        driver = "docker"
        config {
           # for debugging
          #  image = "{{registry_dns}}/{{stack_name}}/prometheus-nats-exporter:{{version_nats_prometheus_exporter_nomadder}}"
            image = "{{registry_dns}}/natsio/prometheus-nats-exporter:{{version_nats_prometheus_exporter}}"
 {% if set_cpu_hard_limit %}
            cpu_hard_limit = "true"
 {% endif %}
            labels = {
                "com.github.logunifier.application.name" = "${NOMAD_ALLOC_NAME}"
                "com.github.logunifier.application.version" = "{{version_nats_prometheus_exporter_nomadder}}"
                "com.github.logunifier.application.pattern.key" = "tslevelmsg"
                "com.github.logunifier.application.org" = "${var.org}"
                "com.github.logunifier.application.env" = "${var.env}"
             }
            ports = ["prometheus_exporter"]
            args = [
              "-varz",
              "-channelz",
              "-connz",
              "-gatewayz",
              "-leafz",
              "-serverz",
              "-subz",
              "-jsz=all",
              "-use_internal_server_name",
              "http://localhost:${NOMAD_PORT_http}"
            ]
        }
      }

    task "nats" {
         volume_mount {
            volume      = "stack_observability_nats_volume"
            destination = "/data/jetstream"
          }
             driver = "docker"
             config {
             image = "{{registry_dns}}/nats:{{version_nats_server}}-alpine"
 {% if set_cpu_hard_limit %}
             cpu_hard_limit = "true"
 {% endif %}
             labels = {
                "com.github.logunifier.application.name" = "nats"
                "com.github.logunifier.application.version" = "{{version_nats_server}}"
                "com.github.logunifier.application.pattern.key" = "tslevelmsg"
                "com.github.logunifier.application.org" = "${var.org}"
                "com.github.logunifier.application.env" = "${var.env}"
             }
             ports = ["client","http","cluster"]
             args = [
               "-c","/config/nats.conf",
               "-js"
             ]
            volumes = [
              "local/nats.conf:/config/nats.conf",
              "local/mappings.conf:/config/mappings.conf",
            ]
             }
          resources {
            cpu    = 500
            memory = 512
            memory_max = 32768
          }
          template {
             destination = "local/nats.conf"
             change_mode = "restart"
             right_delimiter = "++"
             left_delimiter = "++"
             data        = <<EOF
# Client port of ++ env "NOMAD_PORT_client" ++ on all interfaces
port: ++ env "NOMAD_PORT_client" ++

# HTTP monitoring port
monitor_port: ++ env "NOMAD_PORT_http" ++
server_name: "++ env "NOMAD_ALLOC_NAME" ++"
#If true enable protocol trace log messages. Excludes the system account.
trace: false
#If true enable protocol trace log messages. Includes the system account.
trace_verbose: false
#if true enable debug log messages
debug: false
http_port: ++ env "NOMAD_PORT_http" ++
#http: nats.service.consul:++ env "NOMAD_PORT_http" ++

jetstream: enabled
jetstream {
  store_dir: /data/jetstream

  # 1GB
  max_memory_store: 2G

  # 10GB
  max_file_store: 10G
}

include mappings.conf

              EOF
          }

          template {
             destination = "local/mappings.conf"
             change_mode = "restart"
             right_delimiter = "++"
             left_delimiter = "++"
             data        = <<EOF
mappings = {

  # Simple direct mapping.  Messages published to foo are mapped to bar.
  #foo: bar

  # remapping tokens can be done with $<N> representing token position.
  # In this example bar.a.b would be mapped to baz.b.a.
  # bar.*.*: baz.$2.$1

  # You can scope mappings to a particular cluster
  # foo.cluster.scoped : [
  #   { destination: bar.cluster.scoped, weight:100%, cluster: us-west-1 }
  # ]

  # Use weighted mapping for canary testing or A/B testing.  Change dynamically
  # at any time with a server reload.
  # myservice.request: [
  #   { destination: myservice.request.v1, weight: 90% },
  #   { destination: myservice.request.v2, weight: 10% }
  # ]

  # A testing example of wildcard mapping balanced across two subjects.
  # 20% of the traffic is mapped to a service in QA coded to fail.
 # myservice.test.*: [
 #   { destination: myservice.test.$1, weight: 80% },
 #   { destination: myservice.test.fail.$1, weight: 20% }
 # ]

  # A chaos testing trick that introduces 50% artificial message loss of
  # messages published to foo.loss
  #foo.loss.>: [ { destination: foo.loss.>, weight: 50% } ]

  #escaping jinja curly braces
  #devices.*: devices.{{ '{{' }}wildcard(1){{ '}}' }}.{{ '{{' }}partition(10,1){{ '}}' }}
  # {% raw %}
  #  ingress.eventlog.device.*: "ingress.eventlog.device.{{wildcard(1)}}.{{partition(10,1)}}"
  #  egress.eventlog.device.*: "egress.eventlog.device.{{wildcard(1)}}.{{partition(10,1)}}"
  #  ingress.devicetracking.*: "ingress.devicetracking.{{wildcard(1)}}.{{partition(10,1)}}"
  #  egress.devicetracking.*: "egress.devicetracking.{{wildcard(1)}}.{{partition(10,1)}}"
  # {% endraw %}

}
              EOF
          }
       }

    }
   group "blackbox-group" {
      count = 1
      volume "ca_cert" {
        type      = "host"
        source    = "ca_cert"
        read_only = true
      }
      volume "cert_consul" {
        type      = "host"
        source    = "cert_consul"
        read_only = true
      }
      network {
        mode = "bridge"
        port "http" {
          to = 9115
        }
      }
      task "blackbox-task" {
        driver = "docker"
        volume_mount {
          volume      = "ca_cert"
          destination = "/etc/opt/certs/ca"
        }
        volume_mount {
          volume      = "cert_consul"
          destination = "/etc/opt/certs/client"
        }
        config {
          image = "prom/blackbox-exporter:v{{version_blackbox_exporter}}"
          labels = {
            "com.github.logunifier.application.name" = "blackbox-exporter"
            "com.github.logunifier.application.version" = "{{version_blackbox_exporter}}"
            "com.github.logunifier.application.org" = "${var.org}"
            "com.github.logunifier.application.env" = "${var.env}"
          }
 {% if set_cpu_hard_limit %}
          cpu_hard_limit = "true"
 {% endif %}
          ports = ["http"]
          args = ["--config.file","/config/blackbox.yaml"]
          volumes = [
            "local/blackbox.yaml:/config/blackbox.yaml",
          ]
        }
  #Default config from https://raw.githubusercontent.com/prometheus/blackbox_exporter/master/blackbox.yml
  #Example config https://github.com/prometheus/blackbox_exporter/blob/master/example.yml
  # http_integrations module is for validating that the grafana agents scrapping config
  # all the listed integrations must exists
        template {
          right_delimiter = "++"
          left_delimiter = "++"
          data = <<EOF
  modules:
    http_integrations:
      prober: http
      http:
        preferred_ip_protocol: "ip4"
        # Probe fails if response body does not match regex.
        fail_if_body_not_matches_regexp:
          - '.*integration/agent.*'
          - '.*integration/consul.*'
          - '.*integration/node_exporter.*'
          - '.*integration/nomad.*'
        tls_config:
          ca_file: "/etc/opt/certs/ca/cluster-ca-bundle.pem"
          cert_file: "/etc/opt/certs/client/consul.pem"
          key_file: "/etc/opt/certs/client/consul-key.pem"
          insecure_skip_verify: true
                EOF
          destination = "local/blackbox.yaml"
        }


        resources {
          cpu    = 500
          memory = 256
        }

        service {
          name = "blackbox-exporter"
          port = "http"
  #        tags = [
  #          "traefik.enable=true",
  #          "traefik.consulcatalog.connect=false",
  #          "traefik.http.routers.blackbox.tls=true",
  #          "traefik.http.routers.blackbox.rule=Host(`blackbox.cloud.private`)",
  #        ]
          check {
            type     = "tcp"
            port     = "http"
            interval = "10s"
            timeout  = "2s"
            check_restart {
              limit = 3
              grace = "30s"
              ignore_warnings = false
            }
          }
        }
      }
    }
  group "grafana-agent"{
     count = 1

     # Grafana agent is deployed on every node and scrapes the general nomad job metrics
     # This agent deployed for scraping metrics from consul services.
        restart {
          attempts = 1
          interval = "1h"
          delay = "5s"
          mode = "fail"
        }
       volume "stack_observability_grafana_agent_volume" {
          type      = "host"
          source    = "stack_observability_grafana_agent_volume"
          read_only = false
        }
       volume "ca_certs" {
          type      = "host"
          source    = "ca_cert"
          read_only = true
        }
       volume "cert_consul" {
          type      = "host"
          source    = "cert_consul"
          read_only = true
        }
      network {
        mode = "bridge"
        port "server" {}
      }
      service {
           name = "grafana-agent-health"
           #name = "${NOMAD_ALLOC_NAME}-health"
           port = "server"
           check {
              type     = "http"
              port     = "server"
              path     = "/-/healthy"
              interval = "10s"
              timeout  = "2s"
              check_restart {
                limit = 3
                grace = "60s"
                ignore_warnings = false
              }
           }
     }
      service {
           #name = "${NOMAD_ALLOC_NAME}-ready"
           name = "grafana-agent-ready"
           port = "server"
           check {
              type     = "http"
              port     = "server"
              path     = "/-/ready"
              interval = "10s"
              timeout  = "2s"
              check_restart {
                limit = 5
                grace = "60s"
                ignore_warnings = false
              }
           }
     }
    task "grafana-agent" {
         volume_mount {
            volume      = "stack_observability_grafana_agent_volume"
            destination = "/data/wal"
          }
         volume_mount {
            volume      = "ca_certs"
            destination = "/certs/ca"
          }
         volume_mount {
            volume      = "cert_consul"
            destination = "/certs/consul"
          }
       driver = "docker"
       config {
       image = "{{registry_dns}}/grafana/agent:v{{version_grafana_agent_container}}"
 {% if set_cpu_hard_limit %}
         cpu_hard_limit = "true"
 {% endif %}
         labels = {
           "com.github.logunifier.application.name" = "grafana_agent"
           "com.github.logunifier.application.version" = "{{version_grafana_agent_container}}"
           "com.github.logunifier.application.pattern.key" = "logfmt"
           "com.github.logunifier.application.org" = "${var.org}"
           "com.github.logunifier.application.env" = "${var.env}"
         }
         #:${NOMAD_HOST_PORT_server} bind on all available interfaces in the container
         args = [
             "-config.file","/config/agent.yaml", "-server.http.address", ":${NOMAD_HOST_PORT_server}"
          ]
          volumes = [
            "local/agent.yaml:/config/agent.yaml"
        ]
        }
        resources {
          cpu    = 200
          memory = 128
          memory_max = 2048
        }
	   template {
         right_delimiter = "++"
         left_delimiter = "++"
         data = <<EOF
server:
  log_level: info

metrics:
  wal_directory: "/data/wal"
  global:
    scrape_interval: 10s
    remote_write:
++- range service "mimir" ++
      - url: http://++.Name++.service.consul:++.Port++/api/v1/push
++- end ++
  configs:
    - name: integrations
      scrape_configs:
        - job_name: integrations/traefik
          scheme: http
          metrics_path: '/metrics'
          static_configs:
          - targets:
++- range service "traefik" ++
            - ++.Address++:8081
++- end ++

        # grab all metric endpoints with stadanrd /metrics endpoint
        - job_name: "integrations/consul_sd"
          consul_sd_configs:
            - server: "consul.service.consul:8501"
              tags: ["prometheus"]
              tls_config:
                insecure_skip_verify: true
                ca_file: "/certs/ca/ca.crt"
                cert_file: "/certs/consul/consul.pem"
                key_file: "/certs/consul/consul-key.pem"
              datacenter: "{{data_center}}"
              scheme: https
          relabel_configs:
            - source_labels: [__meta_consul_node]
              target_label: instance
            - source_labels: [__meta_consul_service]
              target_label: service
            - source_labels: ['__meta_consul_tags']
              target_label: 'labels'
              regex: '(.+)'
              replacement: '$${1}'
              action: 'keep'
 #           - action: replace
 #             replacement: '1'
 #             target_label: 'test'
          metric_relabel_configs:
            - action: labeldrop
              regex: 'exported_.*'


        - job_name: "integrations/consul_sd_minio"
          metrics_path: "/minio/v2/metrics/cluster"
          consul_sd_configs:
            - server: "consul.service.consul:8501"
              tags: ["prometheus_minio"]
              tls_config:
                insecure_skip_verify: true
                ca_file: "/certs/ca/ca.crt"
                cert_file: "/certs/consul/consul.pem"
                key_file: "/certs/consul/consul-key.pem"
              datacenter: "{{data_center}}"
              scheme: https
          relabel_configs:
            - source_labels: [__meta_consul_node]
              target_label: instance
            - source_labels: [__meta_consul_service]
              target_label: service
            - source_labels: ['__meta_consul_tags']
              target_label: 'labels'
              regex: '(.+)'
              replacement: '$${1}'
              action: 'keep'
          metric_relabel_configs:
            - action: labeldrop
              regex: 'exported_.*'
        - job_name: integrations/blackbox # To get metrics about the exporter itself
          metrics_path: /metrics
          static_configs:
            - targets:
++- range  $index, $service := service "blackbox-exporter" -++
++- if eq $index 0 ++
              - ++.Name++.service.consul:++.Port++
++- end ++
++- end ++
++- if keyExists "blackbox_hosts" ++
        - job_name: integrations/blackbox-checks # To get metrics about the exporter’s targets
          metrics_path: /probe
          params:
            module: [http_integrations]
          static_configs:
            - targets:
++- $hosts := key "blackbox_hosts" -++
++- $hostList := $hosts | split ","  -++
++- range $hostList ++
              - https://++ .| trimSpace ++.node.consul:12345/agent/api/v1/instances
++- end ++
          relabel_configs:
            - source_labels: [__address__]
              target_label: __param_target
            - source_labels: [__param_target]
              target_label: instance
              regex: 'https://(.+)\.node\.consul.*'
              replacement: '$1'
            - target_label: __address__
++- range  $index, $service := service "blackbox-exporter" -++
++- if eq $index 0 ++
              replacement: ++.Name++.service.consul:++.Port++ # The blackbox exporter’s real hostname:port
++- end ++
++- end ++
++- end -++
         EOF
         destination = "local/agent.yaml"
         change_mode = "restart"
       }
#	   template {
#         right_delimiter = "++"
#         left_delimiter = "++"
#         data = file(abspath("./configs/grafana_agent/agent.tpl"))
#         destination = "local/agent.yaml"
#         change_mode = "restart"
#       }
    }
  }
   group "logunifier"{

    restart {
      # logunifier can fail more then once due to waiting for nats, loki and in future to elasticsearch
      attempts = 3
      interval = "1h"
      delay = "5s"
      mode = "fail"
    }
     update {
       max_parallel      = 1
     }
     count = 1
      network {
        mode = "bridge"
        port "health" {
           to= 3000
        }
      }
      service {
           name = "logunifier-health"
           #name = "${NOMAD_ALLOC_NAME}-health"
           port = "health"
           check {
              type     = "http"
              port     = "health"
              path     = "/health"
              interval = "10s"
              timeout  = "2s"
              check_restart {
                limit = 3
                grace = "60s"
                ignore_warnings = false
              }
           }
     }
     task "logunifier" {
     driver = "docker"
            env {
                GOMAXPROCS = "1"
            }
            config {
              image = "{{registry_dns}}/suikast42/logunifier:{{version_logunifer}}"
 {% if set_cpu_hard_limit %}
              cpu_hard_limit = "true"
 {% endif %}
              labels = {
                "com.github.logunifier.application.name" = "logunifier"
                "com.github.logunifier.application.version" = "{{version_logunifer}}"
                "com.github.logunifier.application.pattern.key" = "tslevelmsg"
                "com.github.logunifier.application.strip.ansi" = "true"
                "com.github.logunifier.application.org" = "${var.org}"
                "com.github.logunifier.application.env" = "${var.env}"
              }
              ports = ["health"]
              args = [
                  "-loglevel",
                  "debug",
                  "-natsServers",
                  "nats-observability.service.consul:4222",
                  "-lokiServers",
                  "loki.service.consul:9005",
               ]
             }

           resources {
             cpu    = 500
             memory = 64
             memory_max = 2048
           }
     }
  }
}